{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c9e38a5",
   "metadata": {},
   "source": [
    "\n",
    "# Common pitfalls in the interpretation of coefficients of linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5085cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a2879d",
   "metadata": {},
   "source": [
    "\n",
    "## The dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d87a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "survey = fetch_openml(data_id=534, as_frame=True)\n",
    "X = survey.data[survey.feature_names]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3797b5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = survey.target.values.ravel()\n",
    "survey.target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605f899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380ef8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "categorical_columns = [\"RACE\", \"OCCUPATION\", \"SECTOR\", \"MARR\", \"UNION\", \"SEX\", \"SOUTH\"]\n",
    "numerical_columns = [\"EDUCATION\", \"EXPERIENCE\", \"AGE\"]\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (OneHotEncoder(drop=\"if_binary\"), categorical_columns),\n",
    "    remainder=\"passthrough\",\n",
    "    verbose_feature_names_out=False,  # avoid to prepend the preprocessor names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a09984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "model = make_pipeline(\n",
    "    preprocessor,\n",
    "    TransformedTargetRegressor(\n",
    "        regressor=Ridge(alpha=1e-10), func=np.log10, inverse_func=sp.special.exp10\n",
    "    ),\n",
    ")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd6af3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import median_absolute_error\n",
    "\n",
    "y_pred = model.predict(X_train)\n",
    "\n",
    "mae = median_absolute_error(y_train, y_pred)\n",
    "string_score = f\"MAE on training set: {mae:.2f} $/hour\"\n",
    "y_pred = model.predict(X_test)\n",
    "mae = median_absolute_error(y_test, y_pred)\n",
    "string_score += f\"\\nMAE on testing set: {mae:.2f} $/hour\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208a587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "plt.scatter(y_test, y_pred)\n",
    "ax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\"red\")\n",
    "plt.text(3, 20, string_score)\n",
    "plt.title(\"Ridge model, small regularization\")\n",
    "plt.ylabel(\"Model predictions\")\n",
    "plt.xlabel(\"Truths\")\n",
    "plt.xlim([0, 27])\n",
    "_ = plt.ylim([0, 27])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3cc642",
   "metadata": {},
   "source": [
    "\n",
    "## Interpreting coefficients: scale matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507b7d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = model[:-1].get_feature_names_out()\n",
    "\n",
    "coefs = pd.DataFrame(\n",
    "    model[-1].regressor_.coef_,\n",
    "    columns=[\"Coefficients\"],\n",
    "    index=feature_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec48d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs.plot.barh(figsize=(11, 9))\n",
    "plt.title(\"Ridge model, small regularization\")\n",
    "plt.axvline(x=0, color=\".5\")\n",
    "plt.xlabel(\"Raw coefficient values\")\n",
    "plt.subplots_adjust(left=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e9a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed = pd.DataFrame(\n",
    "    model[:-1].transform(X_train), columns=feature_names\n",
    ")\n",
    "\n",
    "X_train_preprocessed.std(axis=0).plot.barh(figsize=(11, 9))\n",
    "plt.title(\"Feature ranges\")\n",
    "plt.xlabel(\"Std. dev. of feature values\")\n",
    "plt.subplots_adjust(left=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31f98c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = pd.DataFrame(\n",
    "    model[-1].regressor_.coef_ * X_train_preprocessed.std(axis=0),\n",
    "    columns=[\"Coefficient \\nimportance\"],\n",
    "    index=feature_names,\n",
    ")\n",
    "coefs.plot(kind=\"barh\", figsize=(11, 9))\n",
    "plt.xlabel(\"Coefficient values corrected by the feature's std. dev.\")\n",
    "plt.title(\"Ridge model, small regularization\")\n",
    "plt.axvline(x=0, color=\".5\")\n",
    "plt.subplots_adjust(left=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa4e885",
   "metadata": {},
   "source": [
    "\n",
    "## Preprocessing numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d30acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (OneHotEncoder(drop=\"if_binary\"), categorical_columns),\n",
    "    (StandardScaler(), numerical_columns),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eec34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(\n",
    "    preprocessor,\n",
    "    TransformedTargetRegressor(\n",
    "        regressor=Ridge(alpha=1e-10), func=np.log10, inverse_func=sp.special.exp10\n",
    "    ),\n",
    ")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e1aea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = pd.DataFrame(\n",
    "    model[-1].regressor_.coef_,\n",
    "    columns=[\"Coefficient \\nimportance\"],\n",
    "    index=feature_names,\n",
    ")\n",
    "coefs.plot(kind=\"barh\", figsize=(11, 9))\n",
    "plt.xlabel(\"Coefficient values using the standardized features\")\n",
    "plt.title(\"Ridge model, small regularization\")\n",
    "plt.axvline(x=0, color=\".5\")\n",
    "plt.subplots_adjust(left=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e06f108",
   "metadata": {},
   "source": [
    "\n",
    "## Checking the variability of the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a737cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=5, random_state=0)\n",
    "cv_model = cross_validate(\n",
    "    model,\n",
    "    X,\n",
    "    y,\n",
    "    cv=cv,\n",
    "    return_estimator=True,\n",
    "    n_jobs=2,\n",
    ")\n",
    "\n",
    "coefs = pd.DataFrame(\n",
    "    [\n",
    "        est[-1].regressor_.coef_\n",
    "        for est, (train_idx, _) in zip(cv_model[\"estimator\"], cv.split(X, y))\n",
    "    ],\n",
    "    columns=feature_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fdaf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11, 9))\n",
    "sns.stripplot(data=coefs, orient=\"h\", color=\"k\", alpha=0.5)\n",
    "sns.boxplot(data=coefs, orient=\"h\", color=\"cyan\", saturation=0.5, whis=10)\n",
    "plt.axvline(x=0, color=\".5\")\n",
    "plt.xlabel(\"Coefficient importance\")\n",
    "plt.title(\"Coefficient importance and its variability\")\n",
    "plt.suptitle(\"Ridge model, small regularization\")\n",
    "plt.subplots_adjust(left=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2184cc",
   "metadata": {},
   "source": [
    "\n",
    "## The problem of correlated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c7b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylabel(\"Age coefficient\")\n",
    "plt.xlabel(\"Experience coefficient\")\n",
    "plt.grid(True)\n",
    "plt.xlim(-0.4, 0.5)\n",
    "plt.ylim(-0.4, 0.5)\n",
    "plt.scatter(coefs[\"AGE\"], coefs[\"EXPERIENCE\"])\n",
    "_ = plt.title(\"Co-variations of coefficients for \\nAGE and EXPERIENCE across folds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37198f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = X_train.copy()\n",
    "train_dataset.insert(0, \"WAGE\", y_train)\n",
    "_ = sns.pairplot(train_dataset, kind=\"reg\", diag_kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab93d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_drop = [\"AGE\"]\n",
    "numerical_columns = [\"EDUCATION\", \"EXPERIENCE\"]\n",
    "preprocessor = make_column_transformer(\n",
    "    (OneHotEncoder(drop=\"if_binary\"), categorical_columns),\n",
    "    (StandardScaler(), numerical_columns),\n",
    ")\n",
    "model = make_pipeline(\n",
    "    preprocessor,\n",
    "    TransformedTargetRegressor(\n",
    "        regressor=Ridge(alpha=1e-10), func=np.log10, inverse_func=sp.special.exp10\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23f5086",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model = cross_validate(\n",
    "    model,\n",
    "    X.drop(columns=column_to_drop),\n",
    "    y,\n",
    "    cv=cv,\n",
    "    return_estimator=True,\n",
    "    n_jobs=2,\n",
    ")\n",
    "\n",
    "coefs = pd.DataFrame(\n",
    "    [\n",
    "        est[-1].regressor_.coef_\n",
    "        * est[:-1].transform(X.drop(columns=column_to_drop).iloc[train_idx]).std(axis=0)\n",
    "        for est, (train_idx, _) in zip(cv_model[\"estimator\"], cv.split(X, y))\n",
    "    ],\n",
    "    columns=feature_names[:-1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e77ec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11, 9))\n",
    "sns.stripplot(data=coefs, orient=\"h\", color=\"k\", alpha=0.5)\n",
    "sns.boxplot(data=coefs, orient=\"h\", color=\"cyan\", saturation=0.5)\n",
    "plt.axvline(x=0, color=\".5\")\n",
    "plt.title(\"Coefficient importance and its variability\")\n",
    "plt.xlabel(\"Coefficient importance\")\n",
    "plt.suptitle(\"Ridge model, small regularization, AGE dropped\")\n",
    "plt.subplots_adjust(left=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78492fc4",
   "metadata": {},
   "source": [
    "\n",
    "## Linear models with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199293fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [\"EDUCATION\", \"EXPERIENCE\", \"AGE\"]\n",
    "preprocessor = make_column_transformer(\n",
    "    (OneHotEncoder(drop=\"if_binary\"), categorical_columns),\n",
    "    (StandardScaler(), numerical_columns),\n",
    ")\n",
    "model = make_pipeline(\n",
    "    preprocessor,\n",
    "    TransformedTargetRegressor(\n",
    "        regressor=Ridge(alpha=1e-10), func=np.log10, inverse_func=sp.special.exp10\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d502c8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "alphas = np.logspace(-10, 10, 21)  # alpha values to be chosen from by cross-validation\n",
    "model = make_pipeline(\n",
    "    preprocessor,\n",
    "    TransformedTargetRegressor(\n",
    "        regressor=RidgeCV(alphas=alphas),\n",
    "        func=np.log10,\n",
    "        inverse_func=sp.special.exp10,\n",
    "    ),\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "model[-1].regressor_.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d3b365",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model = cross_validate(\n",
    "    model,\n",
    "    X,\n",
    "    y,\n",
    "    cv=cv,\n",
    "    return_estimator=True,\n",
    "    n_jobs=2,\n",
    ")\n",
    "coefs = pd.DataFrame(\n",
    "    [est[-1].regressor_.coef_ for est in cv_model[\"estimator\"]], columns=feature_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6516b16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11, 9))\n",
    "sns.stripplot(data=coefs, orient=\"h\", color=\"k\", alpha=0.5)\n",
    "sns.boxplot(data=coefs, orient=\"h\", color=\"cyan\", saturation=0.5, whis=10)\n",
    "plt.axvline(x=0, color=\".5\")\n",
    "plt.title(\"Coefficient variability\")\n",
    "plt.subplots_adjust(left=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9eb6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
