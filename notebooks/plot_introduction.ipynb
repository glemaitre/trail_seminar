{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af5612e1",
   "metadata": {},
   "source": [
    "\n",
    "# A couple of words regarding statistical modelling\n",
    "\n",
    "## Statistical models\n",
    "\n",
    "![book_model](../images/book_model.jpg)\n",
    "\n",
    "In general, we use statistical models as a simplification of the real\n",
    "underlying problem. We will first contrast different applications of\n",
    "statistical modelling: inference vs. prediction.\n",
    "\n",
    "### Statistical inference\n",
    "\n",
    "Can we understand the dynamics of a given modelisation of the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3d8b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c52287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyworld3 import World3\n",
    "\n",
    "world3 = World3(pyear=2022)\n",
    "world3.init_world3_constants()\n",
    "world3.init_world3_variables()\n",
    "world3.set_world3_table_functions()\n",
    "world3.set_world3_delay_functions()\n",
    "world3.run_world3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadb88bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pyworld3.utils import plot_world_variables\n",
    "\n",
    "plot_world_variables(\n",
    "    world3.time,\n",
    "    [world3.nrfr, world3.iopc, world3.fpc, world3.pop, world3.ppolx],\n",
    "    [\"NRFR\", \"IOPC\", \"FPC\", \"POP\", \"PPOLX\"],\n",
    "    [[0, 1], [0, 1e3], [0, 1e3], [0, 16e9], [0, 32]],\n",
    "    figsize=(16, 10),\n",
    "    title=\"World3 standard run\",\n",
    ")\n",
    "axes = plt.gcf().get_axes()\n",
    "handles = [ax.get_lines()[0] for ax in axes]\n",
    "labels = [\n",
    "    \"Resource\",\n",
    "    \"Industrial output\\n per capita\",\n",
    "    \"Food per capita\",\n",
    "    \"Population\",\n",
    "    \"Pollution\",\n",
    "]\n",
    "_ = plt.legend(handles, labels, loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8987e6",
   "metadata": {},
   "source": [
    "\n",
    "For this specific model, we are not obsessed by the veracity of the forecasts\n",
    "but we want instead to understand the dynamics of the model and the sensitivity\n",
    "to specific parameters. We can therefore\n",
    "use the model to predict different scenarios, highlighting the different\n",
    "trends without attempting to predict perfectly the future.\n",
    "\n",
    "### Predictive modelling\n",
    "\n",
    "When developing a predictive model, we really intend to have the most\n",
    "accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5becbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "iris = load_iris(as_frame=True)\n",
    "X, y = iris.data[[\"sepal width (cm)\", \"petal width (cm)\"]], iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "model = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755b514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "_, ax = plt.subplots(figsize=(10, 8))\n",
    "display = DecisionBoundaryDisplay.from_estimator(model, X_train, alpha=0.5, ax=ax)\n",
    "scatter = display.ax_.scatter(\n",
    "    X_train[\"sepal width (cm)\"], X_train[\"petal width (cm)\"], c=y_train, edgecolor=\"k\"\n",
    ")\n",
    "display.ax_.legend(scatter.legend_elements()[0], iris.target_names)\n",
    "_ = display.ax_.set_title(\"Prediction on training data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9dd736",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(10, 8))\n",
    "display = DecisionBoundaryDisplay.from_estimator(model, X_test, alpha=0.5, ax=ax)\n",
    "scatter = display.ax_.scatter(\n",
    "    X_test[\"sepal width (cm)\"], X_test[\"petal width (cm)\"], c=y_test, edgecolor=\"k\"\n",
    ")\n",
    "display.ax_.legend(scatter.legend_elements()[0], iris.target_names)\n",
    "_ = display.ax_.set_title(\"Prediction on test data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c42e55",
   "metadata": {},
   "source": [
    "\n",
    "We aim at finding the best predictive model, the one that generalizes best on\n",
    "unseen future data.\n",
    "\n",
    "### Why explaining predictive model decisions?\n",
    "\n",
    "- Debug the model (e.g. assumption dataset, feature\n",
    "  engineering, hyperparameters, etc.) to make it work better.\n",
    "- Identify dependences on sensitive features that could reveal\n",
    "  robustness or fairness problems.\n",
    "- (⚠️) Potentially, draw conclusions about the real world assuming\n",
    "  the model is accurate enough.\n",
    "\n",
    "### Association vs. causation\n",
    "\n",
    "Predictive models always find a statistical association (dependence)\n",
    "between `X` and `y`. Most machine-learning models do not attempt to\n",
    "quantify causal effects of `X` on `y`. In particular, most\n",
    "machine-learning models assume i.i.d. data and cannot guarentee to\n",
    "make accurate predictions under intervention.\n",
    "\n",
    "Machine-learning models can be used as building blocks to build\n",
    "causal models but this often requires additional assumptions on the\n",
    "underlying causal graph structure between the variables in `X` and `y`.\n",
    "\n",
    "\n",
    "Here are some specific frameworks intending to use machine-learning for\n",
    "causal inference:\n",
    "\n",
    "- https://github.com/microsoft/EconML\n",
    "- https://github.com/uber/causalml\n",
    "\n",
    "Let's consider 3 scenarios that would produce the same `X` and `y`\n",
    "distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f45c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_data(scenario, n_samples=1_000, seed=None):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    if scenario == \"X causes y\":\n",
    "        X = rng.normal(size=(n_samples,))\n",
    "        y = X + 1 + np.sqrt(3) * rng.normal(size=(n_samples,))\n",
    "    elif scenario == \"y causes X\":\n",
    "        y = 1 + 2 * rng.normal(size=(n_samples,))\n",
    "        X = (y - 1) / 4 + np.sqrt(3) * rng.normal(size=(n_samples,)) / 2\n",
    "    elif scenario == \"Z causes X and y\":\n",
    "        Z = rng.normal(size=(n_samples,))\n",
    "        y = Z + 1 + np.sqrt(3) * rng.normal(size=(n_samples,))\n",
    "        X = Z\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbd6fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario, color in zip(\n",
    "    [\"X causes y\", \"y causes X\", \"Z causes X and y\"],\n",
    "    [\"tab:blue\", \"tab:orange\", \"tab:green\"],\n",
    "):\n",
    "    X, y = generate_data(scenario=scenario, n_samples=100, seed=0)\n",
    "    joint_plot = sns.jointplot(x=X, y=y, color=color)\n",
    "    joint_plot.set_axis_labels(xlabel=scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d6aeaa",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "In terms of distributions, the 3 scenarios are identical. But what causes\n",
    "`X` and `y` are different. Applying a simple linear model on these different\n",
    "dataset will provide the following results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8f38ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario, color in zip(\n",
    "    [\"X causes y\", \"y causes X\", \"Z causes X and y\"],\n",
    "    [\"tab:blue\", \"tab:orange\", \"tab:green\"],\n",
    "):\n",
    "    X, y = generate_data(scenario=scenario, n_samples=100, seed=0)\n",
    "    joint_plot = sns.jointplot(x=X, y=y, color=color, kind=\"reg\")\n",
    "    joint_plot.set_axis_labels(xlabel=scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32780672-2a16-4401-88e4-97b7a93926cf",
   "metadata": {},
   "source": [
    "Courtesy to Ferenc Huszár: [video](https://www.youtube.com/watch?v=HOgx_SBBzn0&t=3855s&ab_channel=MLSSAfrica)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4490c168",
   "metadata": {},
   "source": [
    "\n",
    "### A good explanation of a bad preditive model\n",
    "\n",
    "Before inspecting a model, you should always quantify its predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d218e9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "adult = fetch_openml(\"adult\", version=2)\n",
    "X, y = adult.data.select_dtypes(include=\"number\"), adult.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(),\n",
    ").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa1d9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "coef = pd.Series(model[-1].coef_[0], index=X.columns)\n",
    "_ = coef.plot.barh(figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e7f2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, RepeatedStratifiedKFold\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=0)\n",
    "cv_results = pd.DataFrame(\n",
    "    cross_validate(\n",
    "        model,\n",
    "        X,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        scoring=\"balanced_accuracy\",\n",
    "        return_train_score=True,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157f71fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results[[\"train_score\", \"test_score\"]].aggregate([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92856084-69f8-47ab-bde2-086cc409bd30",
   "metadata": {},
   "source": [
    "Explanations of bad models have no guarantee to give us valid\n",
    "information regarding the real world."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d618b4",
   "metadata": {},
   "source": [
    "\n",
    "## Taxonomy of model explanation techniques\n",
    "\n",
    "### Model specific vs. model agnostic\n",
    "\n",
    "Some models can be considered \"glass-box\" models: it is possible to directly\n",
    "access the association found between\n",
    "`X` and `y`. We can then inspect directly the model and this inspection\n",
    "is therefore model specific. For instance, a linear model exposes the\n",
    "coefficients of the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa8129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.Series(model[-1].coef_[0], index=X.columns)\n",
    "_ = coef.plot.barh(figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4840c0bb",
   "metadata": {},
   "source": [
    "\n",
    "However, some techniques can be applied post-hoc to any type of models and\n",
    "it is therefore model agnostic. In particular, they are useful to gain\n",
    "insights from \"black-box\" models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a237e249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "importances = permutation_importance(\n",
    "    model, X, y, scoring=\"balanced_accuracy\", n_repeats=10, n_jobs=-1\n",
    ")\n",
    "importances = pd.DataFrame(importances.importances.T, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7097bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = importances.plot.box(vert=False, whis=10)\n",
    "_ = ax.set_xlabel(\"Decrease in balanced accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01549c4",
   "metadata": {},
   "source": [
    "\n",
    "### Global explanation vs. local explanation\n",
    "\n",
    "The granularity of the explanation will also depend of the method used. Some\n",
    "methods are only computing a global explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e060fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = importances.plot.box(vert=False, whis=10)\n",
    "_ = ax.set_xlabel(\"Decrease in balanced accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e93e38",
   "metadata": {},
   "source": [
    "\n",
    "Some others are computing a local explanation. This is then possible to get\n",
    "a more global explanation by averaging the local explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f441455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "X_train_preprocessed = pd.DataFrame(\n",
    "    model[:-1].transform(X_train),\n",
    "    columns=model[:-1].get_feature_names_out(),\n",
    ")\n",
    "X_test_preprocessed = pd.DataFrame(\n",
    "    model[:-1].transform(X_test),\n",
    "    columns=model[:-1].get_feature_names_out(),\n",
    ")\n",
    "\n",
    "explainer = shap.Explainer(model[-1], masker=X_train_preprocessed)\n",
    "shap_values = explainer(X_test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e05954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain first test data point\n",
    "shap.plots.waterfall(shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac0900c-050f-4863-8f1e-e6965084459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain second test data point\n",
    "shap.plots.waterfall(shap_values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf06cf6-bf64-4532-b48b-8a45a6248ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global explanation by averaging local explanations\n",
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d5815e-edfc-49a6-894f-8aab9c37de51",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = importances[importances.mean().sort_values().index].plot.box(vert=False, whis=10)\n",
    "_ = ax.set_xlabel(\"Decrease in balanced accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a30f84b",
   "metadata": {},
   "source": [
    "\n",
    "### Decision function explanation vs. loss explanation\n",
    "\n",
    "Some models will only explain the decision function of the model: at no\n",
    "point in time, the true variable `y` will be used to produce the explanation.\n",
    "Some other approaches will quantify the impact of input features on the ability\n",
    "to predict accuractely the true `y`.\n",
    "\n",
    "![shap_vs_sage](../images/shap_vs_sage.png)\n",
    "\n",
    "## Overview of some explanation methods\n",
    "\n",
    "| Method name                               |  Model Agnostic |  Local explanation  |  Global explanation  | Decision function  |  Loss  |\n",
    "|-------------------------------------------|:----------------------:|:-------------------:|:--------------------:|:------------------:|:------:|\n",
    "| Linear model coefficients                 |           ❌           |         ✅          |         ✅           |         ✅          |   ❌   |\n",
    "| Tree-based mean decrease in impurity (MDI)           |           ❌           |         ❌          |         ✅           |         ✅          |   ❌   |\n",
    "| Individual conditional expectation (ICE)  |           ✅           |         ✅          |         ❌           |         ✅          |   ❌   |\n",
    "| Partial dependence plot (PDP)             |           ✅           |         ❌          |         ✅           |         ✅          |   ❌   |\n",
    "| Permutation importance                    |           ✅           |         ❌          |         ✅           |         ❌          |   ✅   |\n",
    "| Shapley additive explanations (SHAP)      |           ✅           |         ✅          |         ✅           |         ✅          |   (✅)  |\n",
    "| Shapley additive global importance (SAGE) |           ✅           |         ❌          |         ✅           |         ❌          |   ✅   |\n",
    "| Conterfactual explanations |           ✅           |         ✅          |         ❌           |         ❌          |   ✅   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d17430-e46a-4d63-9e3a-a9ef239e3751",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[1] Pasqualino, Roberto, et al. \"Understanding global systems today—A calibration of the World3-03 model between 1995 and 2012.\" Sustainability 7.8 (2015): 9864-9889.\n",
    "\n",
    "[2] Molnar, Christoph. Interpretable machine learning. Lulu. com, 2020.\n",
    "\n",
    "[3] Covert, Ian, Scott M. Lundberg, and Su-In Lee. \"Understanding global feature contributions with additive importance measures.\" Advances in Neural Information Processing Systems 33 (2020): 17212-17223."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
