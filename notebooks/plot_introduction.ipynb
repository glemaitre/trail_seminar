{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c26edb59",
   "metadata": {},
   "source": [
    "\n",
    "# A couple of words regarding statistical modelling\n",
    "\n",
    "## Statistical models\n",
    "\n",
    "![book_model](../images/book_model.jpg)\n",
    "\n",
    "In general, we use statistical models as a simplification of the real\n",
    "underlying problem. We will first contrast to different applications of\n",
    "statistical modelling: inference vs. prediction.\n",
    "\n",
    "### Statistical inference\n",
    "\n",
    "Can we understand the dynamics of a given modelisation of the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0af4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ae32fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyworld3 import World3\n",
    "\n",
    "world3 = World3(pyear=2022)\n",
    "world3.init_world3_constants()\n",
    "world3.init_world3_variables()\n",
    "world3.set_world3_table_functions()\n",
    "world3.set_world3_delay_functions()\n",
    "world3.run_world3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81f430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pyworld3.utils import plot_world_variables\n",
    "\n",
    "plot_world_variables(\n",
    "    world3.time,\n",
    "    [world3.nrfr, world3.iopc, world3.fpc, world3.pop, world3.ppolx],\n",
    "    [\"NRFR\", \"IOPC\", \"FPC\", \"POP\", \"PPOLX\"],\n",
    "    [[0, 1], [0, 1e3], [0, 1e3], [0, 16e9], [0, 32]],\n",
    "    figsize=(16, 10),\n",
    "    title=\"World3 standard run\",\n",
    ")\n",
    "axes = plt.gcf().get_axes()\n",
    "handles = [ax.get_lines()[0] for ax in axes]\n",
    "labels = [\n",
    "    \"Resource\",\n",
    "    \"Industrial output\\n per capita\",\n",
    "    \"Food per capita\",\n",
    "    \"Population\",\n",
    "    \"Pollution\",\n",
    "]\n",
    "_ = plt.legend(handles, labels, loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2661f6b0",
   "metadata": {},
   "source": [
    "\n",
    "In inference, we are not generally obsessed by the veracity of the results\n",
    "but we want instead understand the dynamics of the model. We can therefore\n",
    "used the model to predict different scenarios, highlighting the different\n",
    "trends but never at predicting perfectly the future.\n",
    "\n",
    "### Predictive modelling\n",
    "\n",
    "When developing a predictive model, we really intend to have the most\n",
    "accurate model at prediting future values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e47005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "iris = load_iris(as_frame=True)\n",
    "X, y = iris.data[[\"sepal width (cm)\", \"petal width (cm)\"]], iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "model = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387aa2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "_, ax = plt.subplots(figsize=(10, 8))\n",
    "display = DecisionBoundaryDisplay.from_estimator(model, X_train, alpha=0.5, ax=ax)\n",
    "scatter = display.ax_.scatter(\n",
    "    X_train[\"sepal width (cm)\"], X_train[\"petal width (cm)\"], c=y_train, edgecolor=\"k\"\n",
    ")\n",
    "display.ax_.legend(scatter.legend_elements()[0], iris.target_names)\n",
    "_ = display.ax_.set_title(\"Prediction on training data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78545e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(10, 8))\n",
    "display = DecisionBoundaryDisplay.from_estimator(model, X_test, alpha=0.5, ax=ax)\n",
    "scatter = display.ax_.scatter(\n",
    "    X_test[\"sepal width (cm)\"], X_test[\"petal width (cm)\"], c=y_test, edgecolor=\"k\"\n",
    ")\n",
    "display.ax_.legend(scatter.legend_elements()[0], iris.target_names)\n",
    "_ = display.ax_.set_title(\"Prediction on test data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45cd568",
   "metadata": {},
   "source": [
    "\n",
    "We aim at finding the best predictive model, the one that generalizes best on\n",
    "unseen future data.\n",
    "\n",
    "### Association vs. causation\n",
    "\n",
    "Predictive models always find an association between `X` and `y`. They never\n",
    "find a causation: they use probability distributions and do not use causal\n",
    "graphs.\n",
    "\n",
    "Let's consider 3 scenarios that would produce the same `X` and `y`\n",
    "distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a1ed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_data(scenario, n_samples=1_000, seed=None):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    if scenario == \"X causes y\":\n",
    "        X = rng.normal(size=(n_samples,))\n",
    "        y = X + 1 + np.sqrt(3) * rng.normal(size=(n_samples,))\n",
    "    elif scenario == \"y causes X\":\n",
    "        y = 1 + 2 * rng.normal(size=(n_samples,))\n",
    "        X = (y - 1) / 4 + np.sqrt(3) * rng.normal(size=(n_samples,)) / 2\n",
    "    elif scenario == \"Z causes X and y\":\n",
    "        Z = rng.normal(size=(n_samples,))\n",
    "        y = Z + 1 + np.sqrt(3) * rng.normal(size=(n_samples,))\n",
    "        X = Z\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fd0692",
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario, color in zip(\n",
    "    [\"X causes y\", \"y causes X\", \"Z causes X and y\"],\n",
    "    [\"tab:blue\", \"tab:orange\", \"tab:green\"],\n",
    "):\n",
    "    X, y = generate_data(scenario=scenario, n_samples=100, seed=0)\n",
    "    joint_plot = sns.jointplot(x=X, y=y, color=color)\n",
    "    joint_plot.set_axis_labels(xlabel=scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18133b28",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "In terms of distributions, the 3 scenarios are identical. But what causes\n",
    "`X` and `y` are different. Applying a simple linear model on these different\n",
    "dataset will provide the following results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae999eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario, color in zip(\n",
    "    [\"X causes y\", \"y causes X\", \"Z causes X and y\"],\n",
    "    [\"tab:blue\", \"tab:orange\", \"tab:green\"],\n",
    "):\n",
    "    X, y = generate_data(scenario=scenario, n_samples=100, seed=0)\n",
    "    joint_plot = sns.jointplot(x=X, y=y, color=color, kind=\"reg\")\n",
    "    joint_plot.set_axis_labels(xlabel=scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ec61fc",
   "metadata": {},
   "source": [
    "\n",
    "### A predictive model can always be inspected\n",
    "\n",
    "Before inspecting a model, you should always quantify its predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743ba70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "adult = fetch_openml(\"adult\", version=2)\n",
    "X, y = adult.data.select_dtypes(include=\"number\"), adult.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "model = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0534f573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "coef = pd.Series(model.coef_[0], index=X.columns)\n",
    "_ = coef.plot.barh(figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa3d5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, RepeatedStratifiedKFold\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=0)\n",
    "cv_results = pd.DataFrame(\n",
    "    cross_validate(\n",
    "        model,\n",
    "        X,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        scoring=\"balanced_accuracy\",\n",
    "        return_train_score=True,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afec106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results[[\"train_score\", \"test_score\"]].aggregate([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579d8653",
   "metadata": {},
   "source": [
    "\n",
    "## Taxonomy of the explainable techniques\n",
    "\n",
    "### Model specific vs. model agnostic\n",
    "\n",
    "Some models carry some information regarding the association found between\n",
    "`X` and `y`. We can then inspect directly the model and this inspection\n",
    "is therefore model specific. For instance, a linear model exposes the\n",
    "coefficients of the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642ce385",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.Series(model.coef_[0], index=X.columns)\n",
    "_ = coef.plot.barh(figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb0c26d",
   "metadata": {},
   "source": [
    "\n",
    "However, some techniques can be applied post-hoc to any type of models and\n",
    "it is therefore model agnostic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f26649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "importances = permutation_importance(\n",
    "    model, X, y, scoring=\"balanced_accuracy\", n_repeats=10, n_jobs=-1\n",
    ")\n",
    "importances = pd.DataFrame(importances.importances.T, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5843c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = importances.plot.box(vert=False, whis=10)\n",
    "ax.set_xlabel(\"Decrease in balanced accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0b9e9c",
   "metadata": {},
   "source": [
    "\n",
    "### Global explanation vs. local explanation\n",
    "\n",
    "The granularity of the explanation will also depend of the method used. Some\n",
    "methods are only computing a global explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516efdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = importances.plot.box(vert=False, whis=10)\n",
    "ax.set_xlabel(\"Decrease in balanced accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1088788",
   "metadata": {},
   "source": [
    "\n",
    "Some others are computing a local explanation. This is then possible to get\n",
    "a more global explanation by averaging the local explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3236e41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.Explainer(model, masker=X_train)\n",
    "shap_values = explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9850c741",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17708227",
   "metadata": {},
   "source": [
    "\n",
    "### Decision function explanation vs. loss explanation\n",
    "\n",
    "![shap_vs_sage](../images/shap_vs_sage.png)\n",
    "\n",
    "Some models will only explain the decision function of the model: at no\n",
    "point in time, the true variable `y` will be used to produce the explanation.\n",
    "Some other approaches will use the true `y` to compute the explanation."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
