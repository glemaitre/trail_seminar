{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a4a9440",
   "metadata": {},
   "source": [
    "\n",
    "# Exploring the SHAP library\n",
    "\n",
    "In this example, we use the \"Current Population Survey\" dataset, already\n",
    "used in the interpretation of linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf22dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "sklearn.set_config(display=\"diagram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f86a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "survey = fetch_openml(data_id=534, as_frame=True)\n",
    "survey.frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd6c835",
   "metadata": {},
   "source": [
    "\n",
    "The aim is to predict the wage of a person based on set of features such as\n",
    "age, experience, education, etc.\n",
    "\n",
    "We will define a predictive model that uses a gradient-boosting as predictor.\n",
    "Beforehand, the categorical data will be encoded using an\n",
    "`OrdinalEncoder`. These categorical columns are\n",
    "defined by the \"category\" data type reported by pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe6c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey.frame.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10570d3",
   "metadata": {},
   "source": [
    "\n",
    "We reproduce the same experiment setting than with the linear models example:\n",
    "we will use a single train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541d6817",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    survey.data, survey.target, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6112cd4",
   "metadata": {},
   "source": [
    "\n",
    "Let's first define the preprocessing pipeline for the encoding of categorical\n",
    "features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7618f34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "\n",
    "categorical_columns = make_column_selector(dtype_include=\"category\")\n",
    "numerical_columns = make_column_selector(dtype_exclude=\"category\")\n",
    "preprocessor = make_column_transformer(\n",
    "    (\n",
    "        OrdinalEncoder(\n",
    "            handle_unknown=\"use_encoded_value\",\n",
    "            unknown_value=-1,\n",
    "        ),\n",
    "        categorical_columns,\n",
    "    ),\n",
    "    remainder=\"passthrough\",\n",
    "    verbose_feature_names_out=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e314c9ac",
   "metadata": {},
   "source": [
    "\n",
    "Then, we define entire predictive model composed of the preprocessing and the\n",
    "gradient-boosting regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda059fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "model = make_pipeline(\n",
    "    preprocessor,\n",
    "    HistGradientBoostingRegressor(max_iter=10_000, early_stopping=True, random_state=0),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5706fd0",
   "metadata": {},
   "source": [
    "\n",
    "Before to start, we will check the statistical performance of the model.\n",
    "We can compare it with the linear models seen in the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1302a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea39b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print(\n",
    "    f\"MAE on the training set: \"\n",
    "    f\"{mean_absolute_error(y_train, model.predict(X_train)):.3f} $/hour\"\n",
    ")\n",
    "print(\n",
    "    f\"MAE on the training set: \"\n",
    "    f\"{mean_absolute_error(y_test, model.predict(X_test)):.3f} $/hour\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaf4e2d",
   "metadata": {},
   "source": [
    "\n",
    "Now, we use the SHAP library that allows to compute an approximation of the\n",
    "Shapley values. However, before using SHAP, we need to preprocess the data\n",
    "separately due to limited support of some scikit-learn components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3580748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "feature_names = categorical_columns(X_train) + numerical_columns(X_train)\n",
    "X_train_preprocessed = pd.DataFrame(\n",
    "    preprocessor.fit_transform(X_train), columns=feature_names\n",
    ")\n",
    "X_test_preprocessed = pd.DataFrame(\n",
    "    preprocessor.transform(X_test), columns=feature_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73a805a",
   "metadata": {},
   "source": [
    "\n",
    "Now, we use SHAP to get an approximation of the Shapley values for each\n",
    "testing sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683f5e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.Explainer(model[-1], masker=X_train_preprocessed, feature_perturbation=\"interventional\")\n",
    "shap_values = explainer(X_test_preprocessed)\n",
    "shap_values.shape == X_test_preprocessed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1497520",
   "metadata": {},
   "source": [
    "\n",
    "By inspecting `shap_values`, we observe that we get a feature attributions\n",
    "for each data point of the testing set. We can as well see a repeated\n",
    "information called `base_values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb05bcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9836479",
   "metadata": {},
   "source": [
    "\n",
    "Indeed, this base value represents the mean prediction and SHAP is\n",
    "attributing feature values to explain the difference of each prediction\n",
    "of the testing set in regards with the base value.\n",
    "\n",
    "Let's show the SHAP values decomposition for the first sample of the test\n",
    "set. Our model would produce the following value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791a4de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test.iloc[[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2f56eb",
   "metadata": {},
   "source": [
    "\n",
    "The reported SHAP values for the different features are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628a6f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(shap_values[0].values, index=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8214ccbc",
   "metadata": {},
   "source": [
    "\n",
    "Taking into account the base value, then the model prediction corresponds to\n",
    "the following sum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef990f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values[0].values.sum() + shap_values.base_values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb4e001",
   "metadata": {},
   "source": [
    "\n",
    "SHAP package comes with handy plotting facilities to visualize the Shapley\n",
    "values. Let's start by the `waterfall` plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61e6e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442751b5",
   "metadata": {},
   "source": [
    "\n",
    "It represents the graphical summation of the Shapley values for each\n",
    "feature to observe the difference between the expected value and the actual\n",
    "prediction. Another inline representation is the `force` plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d3274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.plots.force(\n",
    "    shap_values.base_values[0],\n",
    "    shap_values.values[0],\n",
    "    feature_names=feature_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ba4a26",
   "metadata": {},
   "source": [
    "\n",
    "We can plot the Shapley values for all samples and encode the color of the\n",
    "features values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc99d042",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f67408",
   "metadata": {},
   "source": [
    "\n",
    "By combining the SHAP values for all samples of the testing set, we can then\n",
    "get a global explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c8a2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6922bc1a",
   "metadata": {},
   "source": [
    "\n",
    "Now, we can make a quick comparison between the Shapley values and the\n",
    "permutation importances. For both, we will make a study of uncertainty by\n",
    "using multiple permutations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ea2504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "importances = permutation_importance(model, X_test, y_test, n_jobs=-1)\n",
    "sorted_idx = importances.importances_mean.argsort()\n",
    "\n",
    "importances = pd.DataFrame(\n",
    "    importances.importances[sorted_idx].T, columns=X_test.columns[sorted_idx]\n",
    ")\n",
    "importances.plot.box(vert=False, whis=100)\n",
    "plt.axvline(0, color=\"k\", linestyle=\"--\")\n",
    "plt.xlabel(\"Decrease in R2 score\")\n",
    "_ = plt.title(\"Permutation importances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461181d0",
   "metadata": {},
   "source": [
    "We can make use of bootstrap resampling of the test set in order to repeat\n",
    "the experiment with a variation of the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e44672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "n_bootstrap = 25\n",
    "\n",
    "all_shap_values = []\n",
    "for _ in range(n_bootstrap):\n",
    "    bootstrap_idx = rng.choice(\n",
    "        np.arange(X_test.shape[0]), size=X_test.shape[0], replace=True\n",
    "    )\n",
    "    X_test_bootstrap = X_test.iloc[bootstrap_idx]\n",
    "    X_test_preprocessed = pd.DataFrame(\n",
    "        preprocessor.transform(X_test_bootstrap), columns=feature_names\n",
    "    )\n",
    "    all_shap_values.append(explainer(X_test_preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdc1770",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = pd.DataFrame(\n",
    "    [np.abs(shap_values.values).mean(axis=0) for shap_values in all_shap_values],\n",
    "    columns=feature_names,\n",
    ")\n",
    "sorted_idx = shap_values.mean().sort_values().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a3f4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values[sorted_idx].plot.box(vert=False, whis=10)\n",
    "plt.xlabel(\"mean(|SHAP values|)\")\n",
    "_ = plt.title(\"SHAP values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e1479d",
   "metadata": {},
   "source": [
    "\n",
    "Comparing the permutation importance and the SHAP values, we observe a\n",
    "difference in the ranking of the features.\n",
    "\n",
    "## Bonus point regarding some SHAP internal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6780f153",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1addb4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.feature_perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a061d681",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(model[-1])\n",
    "explainer(X_test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c4cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.feature_perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163e631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(model[-1], feature_perturbation=\"interventional\")\n",
    "explainer(X_test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c62d3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.feature_perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a972b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([\n",
    "    [[0, 0]] * 400,\n",
    "    [[0, 1]] * 100,\n",
    "    [[1, 0]] * 100,\n",
    "    [[1, 1]] * 400\n",
    "], axis=0)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28ffdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(\n",
    "    [0] * 400 + [50] * 100 + [50] * 100 + [100] * 400\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6bd6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_1 = DecisionTreeRegressor(random_state=0).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a208e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "_ = plot_tree(tree_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f1a110",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_2 = DecisionTreeRegressor(random_state=4).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5486eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "_ = plot_tree(tree_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3735860c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([[1, 1]])\n",
    "explainer = shap.explainers.Exact(tree_1.predict, X)\n",
    "explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea4c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.explainers.Exact(\n",
    "    tree_1.predict, masker=shap.maskers.Independent(X, max_samples=X.shape[0])\n",
    ")\n",
    "explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1501ef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.explainers.Exact(\n",
    "    tree_2.predict, masker=shap.maskers.Independent(X, max_samples=X.shape[0])\n",
    ")\n",
    "explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f54e289",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(tree_1)\n",
    "explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756369f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(tree_2)\n",
    "explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29f55c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4817a4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(tree_1, shap.maskers.Independent(X, max_samples=X.shape[0]))\n",
    "explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5adbf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(tree_2, shap.maskers.Independent(X, max_samples=X.shape[0]))\n",
    "explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a620efda",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
